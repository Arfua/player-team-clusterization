{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script to train embeddings using neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from scipy.constants import pi as pi\n",
    "from scipy.special import binom as binom\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pytorch_utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = utils.get_torch_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"team_color_dataset_splitted/train/\"\n",
    "test_dir = \"team_color_dataset_splitted/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(os.listdir(train_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSoftmaxLinear(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, margin = 4):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.margin = margin\n",
    "\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(in_channels, out_channels))\n",
    "\n",
    "        self.divisor = pi / (self.margin + 1e-5)\n",
    "        self.coeffs = binom(margin, range(0, margin + 1, 2))\n",
    "        self.cos_exps = range(self.margin, -1, -2)\n",
    "        self.sin_sq_exps = range(len(self.cos_exps))\n",
    "        self.signs = [1]\n",
    "        for i in range(1, len(self.sin_sq_exps)):\n",
    "            self.signs.append(self.signs[-1] * -1)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.kaiming_normal_(self.weight.data.t())\n",
    "\n",
    "    def find_k(self, cos):\n",
    "        acos = cos.acos()\n",
    "        k = (acos / self.divisor).floor().detach()\n",
    "        return k\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        if not self.training:\n",
    "            assert y is None\n",
    "            return x.matmul(self.weight)\n",
    "        assert y is not None\n",
    "        logit = x.matmul(self.weight)\n",
    "        batch_size = logit.size(0)\n",
    "        logit_target = logit[range(batch_size), y]\n",
    "        weight_target_norm = self.weight[:, y].norm(p=2, dim=0)\n",
    "        input_norm = x.norm(p=2, dim=1)\n",
    "        # norm_target_prod: (batch_size,)\n",
    "        norm_target_prod = weight_target_norm * input_norm\n",
    "        # cos_target: (batch_size,)\n",
    "        cos_target = logit_target / (norm_target_prod + 1e-10)\n",
    "        sin_sq_target = 1 - cos_target**2\n",
    "\n",
    "        # coeffs, cos_powers, sin_sq_powers, signs: (self.margin // 2 + 1,)\n",
    "        coeffs = torch.tensor(x.data.new(self.coeffs))\n",
    "        cos_exps = torch.tensor(x.data.new(self.cos_exps))\n",
    "        sin_sq_exps = torch.tensor(x.data.new(self.sin_sq_exps))\n",
    "        signs = torch.tensor(x.data.new(self.signs))\n",
    "\n",
    "        cos_terms = cos_target.unsqueeze(1)**cos_exps.unsqueeze(0)\n",
    "        sin_sq_terms = sin_sq_target.unsqueeze(1)**sin_sq_exps.unsqueeze(0)\n",
    "\n",
    "        cosm_terms = signs.unsqueeze(0) * coeffs.unsqueeze(0) * cos_terms * sin_sq_terms\n",
    "        cosm = cosm_terms.sum(1)\n",
    "        k = self.find_k(cos_target)\n",
    "\n",
    "        ls_target = norm_target_prod * (((-1)**k * cosm) - 2 * k)\n",
    "        logit[range(batch_size), y] = ls_target\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LargeMarginCosineLoss(nn.Module):\n",
    "    # TODO: Move parameters to config\n",
    "    def __init__(self, in_channels, out_channels, input_norm=30.0, margin=0.5):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.input_norm = input_norm  # norm of input feature\n",
    "        self.margin = margin  # should be in (0; 1) range\n",
    "        self.weight = Parameter(torch.FloatTensor(out_channels, in_channels))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        if not self.training:\n",
    "            assert y is None\n",
    "            return F.linear(F.normalize(x), self.weight)\n",
    "        assert y is not None\n",
    "        # init cos(theta), phi(theta) was uncovered and included in future transformations\n",
    "        cosine = F.linear(F.normalize(x), F.normalize(self.weight))\n",
    "        # convert y to one-hot\n",
    "        one_hot = torch.tensor(cosine).zero_()\n",
    "        one_hot.scatter_(1, y.view(-1, 1), self.margin)\n",
    "        output = (cosine - one_hot) * self.input_norm\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LargeMarginArcLoss(nn.Module):\n",
    "    # TODO: Move parameters to config\n",
    "    def __init__(self, in_channels, out_channels, input_norm=30.0, margin=0.5, easy_margin=False):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.input_norm = input_norm  # norm of input feature\n",
    "        self.margin = margin  # should be in (0; 1) range\n",
    "        self.weight = Parameter(torch.FloatTensor(out_channels, in_channels))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = np.cos(margin)\n",
    "        self.sin_m = np.sin(margin)\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        if not self.training:\n",
    "            assert y is None\n",
    "            return F.linear(F.normalize(x), self.weight)\n",
    "        assert y is not None\n",
    "        # init cos(theta), sin(theta), phi(theta)\n",
    "        cosine = F.linear(F.normalize(x), F.normalize(self.weight))\n",
    "        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        if not self.easy_margin:\n",
    "            phi = torch.where(cosine > -self.cos_m, phi, cosine - self.margin * self.sin_m)\n",
    "        else:\n",
    "            phi = torch.where(cosine > 0, phi, cosine)\n",
    "        one_hot = torch.tensor(cosine).zero_()\n",
    "        one_hot.scatter_(1, y.view(-1, 1), 1)\n",
    "        output = one_hot * phi + (1.0 - one_hot) * cosine\n",
    "        return output * self.input_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        # size: batch_size, channels, height, width\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.arch()\n",
    "        self.to(device, non_blocking=True, dtype=torch.float32)\n",
    "\n",
    "    def arch(self):\n",
    "        kernel_size = (3, 3)\n",
    "        same = utils.same_padding(kernel_size)\n",
    "        valid = utils.valid_padding(kernel_size)\n",
    "\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=kernel_size, padding=same),\n",
    "            nn.PReLU(16),\n",
    "            nn.BatchNorm2d(16, affine=False))\n",
    "\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 16, kernel_size=kernel_size, padding=valid),\n",
    "            nn.PReLU(16),\n",
    "            nn.BatchNorm2d(16, affine=False),\n",
    "            nn.MaxPool2d((2, 2), stride=2))\n",
    "\n",
    "        self.conv_block3 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=kernel_size, padding=same),\n",
    "            nn.PReLU(32),\n",
    "            nn.BatchNorm2d(32, affine=False))\n",
    "        self.conv_block4 = nn.Sequential(\n",
    "            nn.Conv2d(32, 32, kernel_size=kernel_size, padding=valid),\n",
    "            nn.PReLU(32),\n",
    "            nn.BatchNorm2d(32, affine=False),\n",
    "            nn.MaxPool2d((2, 2), stride=2))\n",
    "\n",
    "        self.embedding = nn.Sequential(\n",
    "            Flatten(),\n",
    "            nn.Linear(32 * 8 * 4, 64),\n",
    "            nn.BatchNorm1d(64, affine=False))\n",
    "        \n",
    "        self.logit = nn.Linear(64, num_classes)\n",
    "        \n",
    "        self.cosine_margin = LargeMarginCosineLoss(in_channels=64, out_channels=num_classes)\n",
    "        self.arc_margin = LargeMarginArcLoss(in_channels=64, out_channels=num_classes)\n",
    "        self.large_margin = LSoftmaxLinear(in_channels=64, out_channels=num_classes)\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def predict(self, x):\n",
    "        x = torch.from_numpy(x).permute(0, 3, 1, 2).float().div(255)\n",
    "        x = torch.tensor(x, dtype=torch.float).to(device, non_blocking=True, dtype=torch.float32)\n",
    "        return self(x)\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        out = self.conv_block1(x)\n",
    "        out = self.conv_block2(out)\n",
    "        out = self.conv_block3(out)\n",
    "        out = self.conv_block4(out)\n",
    "        embeddings = self.embedding(out)\n",
    "        logit = self.logit(embeddings)\n",
    "        return logit, embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineMarginNet(Net):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, x, y=None):\n",
    "        out = self.conv_block1(x)\n",
    "        out = self.conv_block2(out)\n",
    "        out = self.conv_block3(out)\n",
    "        out = self.conv_block4(out)\n",
    "        embeddings = self.embedding(out)\n",
    "        logit = self.cosine_margin(embeddings, y)\n",
    "        return logit, embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArcMarginNet(Net):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, x, y=None):\n",
    "        out = self.conv_block1(x)\n",
    "        out = self.conv_block2(out)\n",
    "        out = self.conv_block3(out)\n",
    "        out = self.conv_block4(out)\n",
    "        embeddings = self.embedding(out)\n",
    "        logit = self.arc_margin(embeddings, y)\n",
    "        return logit, embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LargeMarginNet(Net):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, x, y=None):\n",
    "        out = self.conv_block1(x)\n",
    "        out = self.conv_block2(out)\n",
    "        out = self.conv_block3(out)\n",
    "        out = self.conv_block4(out)\n",
    "        embeddings = self.embedding(out)\n",
    "        logit = self.large_margin(embeddings, y)\n",
    "        return logit, embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(7),\n",
    "    transforms.RandomAffine(0, translate=(0.1, 0.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(utils.to_bgr_transform)])\n",
    "transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Lambda(utils.to_bgr_transform)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = ImageFolder(train_dir, transform=transform_train)\n",
    "test_set = ImageFolder(test_dir, transform=transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "train_loader = DataLoader(\n",
    "    train_set, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(\n",
    "    test_set, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "num_classes = len(train_loader.dataset.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, epoch):\n",
    "    optimizer = Adam(net.parameters(), lr=0.003, weight_decay=0.00005)\n",
    "    net.train()\n",
    "    total_loss = 0\n",
    "    mini_batch_step = 200\n",
    "\n",
    "    for batch_step, (x, y) in enumerate(train_loader):\n",
    "        writer_step = epoch * len(train_loader) + batch_step\n",
    "        x = torch.tensor(x).to(device)\n",
    "        y = torch.tensor(y).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output, _ = net(x, y)\n",
    "\n",
    "        loss = criterion(input=output, target=y).to(device)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        if batch_step % mini_batch_step == mini_batch_step - 1:\n",
    "            log_step_loss = total_loss / mini_batch_step\n",
    "            print(\n",
    "                f\"Train Epoch: {epoch} [{batch_step * len(x)}/{len(train_loader.dataset)} \"\n",
    "                f\"({100 * batch_step / len(train_loader):.0f}%)]\\tLoss: {log_step_loss:.6f}\")\n",
    "            total_loss = 0\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(net, epoch, data_loader, set_name):\n",
    "        net.eval()  # Reqired parameter in evaluation mode\n",
    "        num_correct = total_loss = 0\n",
    "        with torch.no_grad():  # Turns off gradient update\n",
    "            for batch_step, (x, y) in enumerate(data_loader):\n",
    "                pos_true_batch = sum(y == 1).item()\n",
    "                writer_step = epoch * len(train_loader) + batch_step\n",
    "                x = torch.tensor(x, requires_grad=False).to(device)\n",
    "                y = torch.tensor(y, requires_grad=False).to(device)\n",
    "\n",
    "                output, _ = net(x)\n",
    "\n",
    "                y_pred = output.data.max(1)[1]\n",
    "                # Alternative prediction calculation\n",
    "                # _, y_pred = torch.max(output, 1)\n",
    "                loss = criterion(input=output, target=y).to(device)\n",
    "                total_loss += loss.item()\n",
    "                num_correct += y_pred.eq(y).long().sum().item()\n",
    "            average_loss = total_loss / len(data_loader)\n",
    "            accuracy = num_correct / len(data_loader.dataset) * 100\n",
    "        print(\n",
    "            f\"{set_name} set:\\tLoss: {average_loss:.6f} Accuracy: {num_correct}/{len(data_loader.dataset)} \"\n",
    "            f\"({accuracy:.4f} %)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = CosineMarginNet()\n",
    "for epoch in range(1, 5):\n",
    "    train(net, epoch)\n",
    "    evaluate(net, epoch, train_loader, set_name=\"Train\")\n",
    "    evaluate(net, epoch, test_loader, set_name=\"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = 'groups_to_cluster_from_tracker/olimpic__0-82__groups/'\n",
    "files = sorted([src_path + x for x in os.listdir(src_path)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for file in files:\n",
    "    images.append(cv2.resize(cv2.imread(file), (25, 40)))\n",
    "images = np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.array([]).reshape((0, 64))\n",
    "for batch in np.split(images, images.shape[0] / 1024):\n",
    "    embeddings = np.concatenate([embeddings, np.array(net.predict(batch)[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = pd.DataFrame(embeddings)\n",
    "y_df = pd.Series([[person_type in f for person_type in [\"referee\", \"team1\", \"team2\"]].index(True) for f in files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df.to_pickle(\"X_df_embed\")\n",
    "y_df.to_pickle(\"y_df_embed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
